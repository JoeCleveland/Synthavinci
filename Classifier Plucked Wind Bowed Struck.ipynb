{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "import matplotlib.pyplot as plt\n",
    "import soundfile as sf\n",
    "import librosa as rosa\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "from sklearn import svm\n",
    "import os\n",
    "#from keras.layers import Dense,Dropout\n",
    "#from keras.models import Sequential\n",
    "#from keras.regularizers import l2\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Saving audio samples in List called 'sound' \"\"\"\n",
    "\n",
    "i = 0\n",
    "sound = []\n",
    "path = 'C:/Users/arshi/Desktop/nsynth-valid/audio/'\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    audio, rate = sf.read(path + filename)\n",
    "    mfccs = rosa.feature.mfcc(audio, sr=rate)\n",
    "    average = np.mean(mfccs, axis = 1)\n",
    "    sound.append(average)\n",
    "    print(i)\n",
    "    i=i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12274\n"
     ]
    }
   ],
   "source": [
    "print(len(sound))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12274\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Saving classification codes - pl,wi,bo,ha - in List called 'instrument' \n",
    " (2638) - 1 - 2638 - bass - pl\n",
    " (886) - 2639 - 2702 - brass - wi\n",
    " (470) - 2703 - 3173 - flute - wi\n",
    " (2081) - 3174 - 5255 - guitar - pl\n",
    " (2404) - 5256 - 7660 - keyboard - ha\n",
    " (663) - 7661 - 8324 - mallet - ha\n",
    " (1598) - 8325 - 9923 - organ - wi\n",
    " (720) - 9924 - 10644 - reed - wi\n",
    " (814) - 10645 - 11459 - string - bo\n",
    " \n",
    " \"\"\"\n",
    "\n",
    "instrument = []\n",
    "for i in range (0, 2638):\n",
    "    instrument.append('pl')\n",
    "for i in range (0,886):\n",
    "    instrument.append('wi')\n",
    "for i in range (0,470):\n",
    "    instrument.append('wi')\n",
    "for i in range (0,2081):\n",
    "    instrument.append('pl')\n",
    "for i in range (0,2404):\n",
    "    instrument.append('st')\n",
    "for i in range (0,663):\n",
    "    instrument.append('st')\n",
    "for i in range (0,1598):\n",
    "    instrument.append('wi')\n",
    "for i in range (0,720):\n",
    "    instrument.append('wi')\n",
    "for i in range (0,814):\n",
    "    instrument.append('bo')\n",
    "    \n",
    "print(len(instrument))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Splitting between test and train\"\"\"\n",
    "\n",
    "\n",
    "sound_train, sound_test, instrument_train, instrument_test = train_test_split(sound, instrument, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3683\n"
     ]
    }
   ],
   "source": [
    "print(len(instrument_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Keras neural network \n",
    "https://towardsdatascience.com/k-as-in-keras-simple-classification-model-a9d2d23d5b5a\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Hidden Layer 1\n",
    "model.add(Dense(100,activation='relu',input_dim=8,kernel_regularization=12(0.01)))\n",
    "model.add(Dropout(0.3,noise_shape=None, seed=None))\n",
    "\n",
    "#Hidden Layer 2 \n",
    "model.add(Dense(100,activation='relu',kernal_regularization=12(0.01)))\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" Model Compile \"\"\"\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Train the model\"\"\"\n",
    "\n",
    "model_output = model.fit(sound_train, instrument_train, epochs=10, batch_size=20,verbose=1,validatondata=(sound_test,instrument_test),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Training accuracy :',np.mean(model_output.history[\"acc\"]))\n",
    "print('Validatoin accuracy :',np.mean(model_output.history[\"val_acc\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovo', degree=3, gamma='scale', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" SVM \"\"\"\n",
    "\n",
    "clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "clf.fit(sound_train, instrument_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=(clf.predict(sound_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61.851751289709476\n"
     ]
    }
   ],
   "source": [
    "score = 0\n",
    "for i in range (0,3683):\n",
    "    if result[i] == instrument_test[i]:\n",
    "        score = score +1\n",
    "    else:\n",
    "        score = score\n",
    "print(score/3683 * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    " Stole Neural Network code from - https://github.com/ankonzoid/NN-from-scratch\n",
    " \n",
    " NeuralNetwork.py  (author: Anson Wong / git: ankonzoid)\n",
    "\"\"\"\n",
    "import math, random\n",
    "import numpy as np\n",
    "\n",
    "class NeuralNetwork:\n",
    "\n",
    "    def __init__(self, input_dim=None, output_dim=None, hidden_layers=None, seed=1):\n",
    "        if (input_dim is None) or (output_dim is None) or (hidden_layers is None):\n",
    "            raise Exception(\"Invalid arguments given!\")\n",
    "        self.input_dim = input_dim # number of input nodes\n",
    "        self.output_dim = output_dim # number of output nodes\n",
    "        self.hidden_layers = hidden_layers # number of hidden nodes @ each layer\n",
    "        self.network = self._build_network(seed=seed)\n",
    "\n",
    "    # Train network\n",
    "    def train(self, X, y, eta=0.5, n_epochs=200):\n",
    "        for epoch in range(n_epochs):\n",
    "            for (x_, y_) in zip(X, y):\n",
    "                self._forward_pass(x_) # forward pass (update node[\"output\"])\n",
    "                yhot_ = self._one_hot_encoding(y_, self.output_dim) # one-hot target\n",
    "                self._backward_pass(yhot_) # backward pass error (update node[\"delta\"])\n",
    "                self._update_weights(x_, eta) # update weights (update node[\"weight\"])\n",
    "\n",
    "    # Predict using argmax of logits\n",
    "    def predict(self, X):\n",
    "        ypred = np.array([np.argmax(self._forward_pass(x_)) for x_ in X], dtype=np.int)\n",
    "        return ypred\n",
    "\n",
    "    # ==============================\n",
    "    #\n",
    "    # Internal functions\n",
    "    #\n",
    "    # ==============================\n",
    "\n",
    "    # Build fully-connected neural network (no bias terms)\n",
    "    def _build_network(self, seed=1):\n",
    "        random.seed(seed)\n",
    "\n",
    "        # Create a single fully-connected layer\n",
    "        def _layer(input_dim, output_dim):\n",
    "            layer = []\n",
    "            for i in range(output_dim):\n",
    "                weights = [random.random() for _ in range(input_dim)] # sample N(0,1)\n",
    "                node = {\"weights\": weights, # list of weights\n",
    "                        \"output\": None, # scalar\n",
    "                        \"delta\": None} # scalar\n",
    "                layer.append(node)\n",
    "            return layer\n",
    "\n",
    "        # Stack layers (input -> hidden -> output)\n",
    "        network = []\n",
    "        if len(self.hidden_layers) == 0:\n",
    "            network.append(_layer(self.input_dim, self.output_dim))\n",
    "        else:\n",
    "            network.append(_layer(self.input_dim, self.hidden_layers[0]))\n",
    "            for i in range(1, len(self.hidden_layers)):\n",
    "                network.append(_layer(self.hidden_layers[i-1], self.hidden_layers[i]))\n",
    "            network.append(_layer(self.hidden_layers[-1], self.output_dim))\n",
    "\n",
    "        return network\n",
    "\n",
    "    # Forward-pass (updates node['output'])\n",
    "    def _forward_pass(self, x):\n",
    "        transfer = self._sigmoid\n",
    "        x_in = x\n",
    "        for layer in self.network:\n",
    "            x_out = []\n",
    "            for node in layer:\n",
    "                node['output'] = transfer(self._dotprod(node['weights'], x_in))\n",
    "                x_out.append(node['output'])\n",
    "            x_in = x_out # set output as next input\n",
    "        return x_in\n",
    "\n",
    "    # Backward-pass (updates node['delta'], L2 loss is assumed)\n",
    "    def _backward_pass(self, yhot):\n",
    "        transfer_derivative = self._sigmoid_derivative # sig' = f(sig)\n",
    "        n_layers = len(self.network)\n",
    "        for i in reversed(range(n_layers)): # traverse backwards\n",
    "            if i == n_layers - 1:\n",
    "                # Difference between logits and one-hot target\n",
    "                for j, node in enumerate(self.network[i]):\n",
    "                    err = node['output'] - yhot[j]\n",
    "                    node['delta'] = err * transfer_derivative(node['output'])\n",
    "            else:\n",
    "                # Weighted sum of deltas from upper layer\n",
    "                for j, node in enumerate(self.network[i]):\n",
    "                    err = sum([node_['weights'][j] * node_['delta'] for node_ in self.network[i+1]])\n",
    "                    node['delta'] = err * transfer_derivative(node['output'])\n",
    "\n",
    "    # Update weights (updates node['weight'])\n",
    "    def _update_weights(self, x, eta):\n",
    "        for i, layer in enumerate(self.network):\n",
    "            # Grab input values\n",
    "            if i == 0: inputs = x\n",
    "            else: inputs = [node_['output'] for node_ in self.network[i-1]]\n",
    "            # Update weights\n",
    "            for node in layer:\n",
    "                for j, input in enumerate(inputs):\n",
    "                    # dw = - learning_rate * (error * transfer') * input\n",
    "                    node['weights'][j] += - eta * node['delta'] * input\n",
    "\n",
    "    # Dot product\n",
    "    def _dotprod(self, a, b):\n",
    "        return sum([a_ * b_ for (a_, b_) in zip(a, b)])\n",
    "\n",
    "    # Sigmoid (activation function)\n",
    "    def _sigmoid(self, x):\n",
    "        return 1.0/(1.0+math.exp(-x))\n",
    "\n",
    "    # Sigmoid derivative\n",
    "    def _sigmoid_derivative(self, sigmoid):\n",
    "        return sigmoid*(1.0-sigmoid)\n",
    "\n",
    "    # One-hot encoding\n",
    "    def _one_hot_encoding(self, idx, output_dim):\n",
    "        x = np.zeros(output_dim, dtype=np.int)\n",
    "        x[idx] = 1\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> len(sound_train) = 8591, len(instrument_shape) = 8591, n_classes = 4\n",
      "\n",
      "Neural network model:\n",
      " input_dim = 8591\n",
      " hidden_layers = [5]\n",
      " output_dim = 4\n",
      " eta = 0.1\n",
      " n_epochs = 400\n",
      " n_folds = 4\n",
      " seed_crossval = 1\n",
      " seed_weights = 1\n",
      "\n",
      "Cross-validating with 4 folds...\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-572a48990664>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;31m# Driver\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-29-572a48990664>\u001b[0m in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     61\u001b[0m         model = NeuralNetwork(input_dim=d, output_dim=n_classes,\n\u001b[0;32m     62\u001b[0m                               hidden_layers=hidden_layers, seed=seed_weights)\n\u001b[1;32m---> 63\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msound_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minstrument_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0meta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m         \u001b[1;31m# Make predictions for training and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a1adbfef557e>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, X, y, eta, n_epochs)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# forward pass (update node[\"output\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m                 \u001b[0myhot_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_one_hot_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# one-hot target\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backward_pass\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myhot_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# backward pass error (update node[\"delta\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_weights\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meta\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# update weights (update node[\"weight\"])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-a1adbfef557e>\u001b[0m in \u001b[0;36m_one_hot_encoding\u001b[1;34m(self, idx, output_dim)\u001b[0m\n\u001b[0;32m    119\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_one_hot_encoding\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_dim\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m         \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    " NN_classifier.py  (author: Anson Wong / git: ankonzoid)\n",
    " We train a multi-layer fully-connected neural network from scratch to classify\n",
    " the seeds dataset (https://archive.ics.uci.edu/ml/datasets/seeds). An L2 loss\n",
    " function, sigmoid activation, and no bias terms are assumed. The weight\n",
    " optimization is gradient descent via the delta rule.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import utils as utils\n",
    "\n",
    "def main():\n",
    "    # ===================================\n",
    "    # Settings\n",
    "    # ===================================\n",
    "    csv_filename = \"data/seeds_dataset.csv\"\n",
    "    hidden_layers = [5] # number of nodes in hidden layers i.e. [layer1, layer2, ...]\n",
    "    eta = 0.1 # learning rate\n",
    "    n_epochs = 400 # number of training epochs\n",
    "    n_folds = 4 # number of folds for cross-validation\n",
    "    seed_crossval = 1 # seed for cross-validation\n",
    "    seed_weights = 1 # seed for NN weight initialization\n",
    "\n",
    "    # ===================================\n",
    "    # Read csv data + normalize features\n",
    "    # ===================================\n",
    "    #print(\"Reading '{}'...\".format(csv_filename))\n",
    "    n_classes = 4\n",
    "    d = len(sound_train)\n",
    "    N = len(sound_train)\n",
    "    print(\" -> len(sound_train) = {}, len(instrument_shape) = {}, n_classes = {}\\n\".format(len(sound_train), len(instrument_train), n_classes))\n",
    "\n",
    "    print(\"Neural network model:\")\n",
    "    print(\" input_dim = {}\".format(d))\n",
    "    print(\" hidden_layers = {}\".format(hidden_layers))\n",
    "    print(\" output_dim = {}\".format(n_classes))\n",
    "    print(\" eta = {}\".format(eta))\n",
    "    print(\" n_epochs = {}\".format(n_epochs))\n",
    "    print(\" n_folds = {}\".format(n_folds))\n",
    "    print(\" seed_crossval = {}\".format(seed_crossval))\n",
    "    print(\" seed_weights = {}\\n\".format(seed_weights))\n",
    "\n",
    "    # ===================================\n",
    "    # Create cross-validation folds\n",
    "    # ===================================\n",
    "    idx_all = np.arange(0, N)\n",
    "    idx_folds = utils.crossval_folds(N, n_folds, seed=seed_crossval) # list of list of fold indices\n",
    "\n",
    "    # ===================================\n",
    "    # Train/evaluate the model on each fold\n",
    "    # ===================================\n",
    "    acc_train, acc_valid = list(), list()  # training/test accuracy score\n",
    "    print(\"Cross-validating with {} folds...\".format(len(idx_folds)))\n",
    "    for i, idx_valid in enumerate(idx_folds):\n",
    "\n",
    "        # Collect training and test data from folds\n",
    "        #idx_train = np.delete(idx_all, idx_valid)\n",
    "        #X_train, y_train = X[idx_train], y[idx_train]\n",
    "        #X_valid, y_valid = X[idx_valid], y[idx_valid]\n",
    "\n",
    "        # Build neural network classifier model and train\n",
    "        model = NeuralNetwork(input_dim=d, output_dim=n_classes,\n",
    "                              hidden_layers=hidden_layers, seed=seed_weights)\n",
    "        model.train(sound_train, instrument_train, eta=eta, n_epochs=n_epochs)\n",
    "\n",
    "        # Make predictions for training and test data\n",
    "        ypred_train = model.predict(X_train)\n",
    "        ypred_valid = model.predict(X_valid)\n",
    "\n",
    "        # Compute training/test accuracy score from predicted values\n",
    "        acc_train.append(100*np.sum(y_train==ypred_train)/len(y_train))\n",
    "        acc_valid.append(100*np.sum(y_valid==ypred_valid)/len(y_valid))\n",
    "\n",
    "        # Print cross-validation result\n",
    "        print(\" Fold {}/{}: acc_train = {:.2f}%, acc_valid = {:.2f}% (n_train = {}, n_valid = {})\".format(\n",
    "            i+1, n_folds, acc_train[-1], acc_valid[-1], len(X_train), len(X_valid)))\n",
    "\n",
    "    # ===================================\n",
    "    # Print results\n",
    "    # ===================================\n",
    "    print(\"  -> acc_train_avg = {:.2f}%, acc_valid_avg = {:.2f}%\".format(\n",
    "        sum(acc_train)/float(len(acc_train)), sum(acc_valid)/float(len(acc_valid))))\n",
    "\n",
    "# Driver\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f42388df1e8f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" Training a model \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Hidden Layer 1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\" Training a model \"\"\"\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "#Hidden Layer 1\n",
    "model.add(Dense(100,activation='relu',input_dim=8,kernel_regularization=12(0.01)))\n",
    "model.add(Dropout(0.3,noise_shape=None, seed=None))\n",
    "\n",
    "#Hidden Layer 2 \n",
    "model.add(Dense(100,activation='relu',kernal_regularization=12(0.01)))\n",
    "model.add(Dropout(0.3, noise_shape=None, seed=None))\n",
    "\n",
    "#Output Layer\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-775e4263329d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;34m\"\"\" Predicting \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msound_test\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    574\u001b[0m             \u001b[0mClass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    575\u001b[0m         \"\"\"\n\u001b[1;32m--> 576\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBaseSVC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    577\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    578\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    323\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    324\u001b[0m         \"\"\"\n\u001b[1;32m--> 325\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_for_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    326\u001b[0m         \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse_predict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_predict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\svm\\base.py\u001b[0m in \u001b[0;36m_validate_for_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         X = check_array(X, accept_sparse='csr', dtype=np.float64, order=\"C\",\n\u001b[1;32m--> 458\u001b[1;33m                         accept_large_sparse=False)\n\u001b[0m\u001b[0;32m    459\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misspmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\venv\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    569\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[1;32m--> 570\u001b[1;33m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[0;32m    571\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "\"\"\" Predicting \"\"\"\n",
    "\n",
    "clf.predict([[sound_test]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Training a model\"\"\"\n",
    "\n",
    "def train(data, method):\n",
    "    #src_names, features, labels = unpack_data(data)\n",
    "    #print 'train feature vector dim:', features.shape\n",
    "\n",
    "    # initialize models (not all used)\n",
    "    params = method[0]\n",
    "    pca = decomposition.PCA(n_components=params['pca_n'])\n",
    "    svc = svm.LinearSVC()\n",
    "    knn = neighbors.KNeighborsClassifier(n_neighbors=params['knn_k'], metric=params['knn_metric'])\n",
    "\n",
    "    if 'pca' in method:\n",
    "        features = pca.fit_transform(features)\n",
    "\n",
    "    if 'svc' in method:\n",
    "        svc.fit(features, labels)\n",
    "\n",
    "    if 'knn' in method:\n",
    "        knn.fit(features, labels)\n",
    "\n",
    "    return pca, svc, knn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
